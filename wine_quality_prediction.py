# -*- coding: utf-8 -*-
"""Wine Quality Prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18u_f7mKuijtLkM2GOiAjlfavDnNqSkTi
"""

!pip install streamlit
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import streamlit as st

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.tree import plot_tree

pd.set_option('display.max_columns', None)
plt.style.use('seaborn-v0_8-darkgrid')

print("="*70)
print("ğŸ· WINE QUALITY PREDICTION PROJECT")
print("="*70)
print("âœ… All libraries imported successfully!\n")

url = "https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv"
df = pd.read_csv(url, sep=';')

print("âœ… Dataset loaded successfully!")
print(f"ğŸ“Š Dataset shape: {df.shape[0]} rows Ã— {df.shape[1]} columns\n")
print("="*70)

print("\nğŸ” FIRST 5 ROWS OF THE DATASET:")
print(df.head())
print("\n" + "-"*70)

print("\nğŸ“‹ DATASET INFORMATION:")
print(df.info())
print("\n" + "-"*70)

print("\nğŸ“ˆ STATISTICAL SUMMARY:")
print(df.describe())
print("\n" + "-"*70)

print("\nğŸ¯ QUALITY DISTRIBUTION (Target Variable):")
quality_dist = df['quality'].value_counts().sort_index()
print(quality_dist)
print(f"\nMost common quality: {quality_dist.idxmax()} (appears {quality_dist.max()} times)")
print("\n" + "="*70)

print("\nğŸ“Š Generating visualizations...")

fig, axes = plt.subplots(2, 2, figsize=(14, 10))
fig.suptitle('Wine Quality Dataset - Exploratory Analysis', fontsize=16, fontweight='bold')

axes[0, 0].hist(df['quality'], bins=6, color='skyblue', edgecolor='black')
axes[0, 0].set_title('Distribution of Wine Quality Ratings', fontsize=12, fontweight='bold')
axes[0, 0].set_xlabel('Quality Rating')
axes[0, 0].set_ylabel('Number of Wines')
axes[0, 0].grid(axis='y', alpha=0.3)

axes[0, 1].scatter(df['alcohol'], df['quality'], alpha=0.5, color='coral')
axes[0, 1].set_title('Alcohol Content vs Quality', fontsize=12, fontweight='bold')
axes[0, 1].set_xlabel('Alcohol (%)')
axes[0, 1].set_ylabel('Quality Rating')
axes[0, 1].grid(alpha=0.3)

axes[1, 0].scatter(df['pH'], df['quality'], alpha=0.5, color='lightgreen')
axes[1, 0].set_title('pH Level vs Quality', fontsize=12, fontweight='bold')
axes[1, 0].set_xlabel('pH Level')
axes[1, 0].set_ylabel('Quality Rating')
axes[1, 0].grid(alpha=0.3)

correlation = df.corr()
sns.heatmap(correlation[['quality']].sort_values(by='quality', ascending=False),
            annot=True, cmap='coolwarm', ax=axes[1, 1], cbar=True, fmt='.2f')
axes[1, 1].set_title('Feature Correlation with Quality', fontsize=12, fontweight='bold')

plt.tight_layout()
plt.show()

print("âœ… Visualizations generated!\n")
print("="*70)

print("\nğŸ”§ PREPROCESSING DATA...")

X = df.drop('quality', axis=1)
y = df['quality']

print(f"âœ… Features (X) shape: {X.shape}")
print(f"âœ… Target (y) shape: {y.shape}")

print(f"\nğŸ“ Features used for prediction:")
for i, col in enumerate(X.columns, 1):
    print(f"   {i}. {col}")

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

print(f"\nâœ… Data split complete!")
print(f"   ğŸ“š Training set: {X_train.shape[0]} samples ({(X_train.shape[0]/len(df)*100):.1f}%)")
print(f"   ğŸ§ª Testing set: {X_test.shape[0]} samples ({(X_test.shape[0]/len(df)*100):.1f}%)")
print("\n" + "="*70)

model = DecisionTreeClassifier(
    max_depth=5,
    min_samples_split=20,
    min_samples_leaf=10,
    random_state=42
)

print("âœ… Model created with parameters:")
print(f"   - Max Depth: 5")
print(f"   - Min Samples Split: 20")
print(f"   - Min Samples Leaf: 10")

print("\nğŸ“ Training the model...")
model.fit(X_train, y_train)
print("âœ… Model training complete!")
print("\n" + "="*70)

print("\nğŸ”® MAKING PREDICTIONS ON TEST SET...")

y_pred = model.predict(X_test)

print("âœ… Predictions complete!")
print(f"\nğŸ“‹ Sample predictions vs actual values:")
print(f"{'Predicted':<12} {'Actual':<10} {'Match':<10}")
print("-" * 35)
for i in range(10):
  match = "âœ“" if y_pred[i] == y_test.iloc[i] else "âœ—"
print(f"{y_pred[i]:<12} {y_test.iloc[i]:<10} {match:<10}")
print("\n" + "="*70)

print("\nğŸ“Š MODEL EVALUATION")
print("="*70)

accuracy = accuracy_score(y_test, y_pred)
print(f"\nğŸ¯ OVERALL ACCURACY: {accuracy * 100:.2f}%")
print(f"   (Correctly predicted {int(accuracy * len(y_test))} out of {len(y_test)} wines)")

print("\nğŸ“Š DETAILED CLASSIFICATION REPORT:")
print("-"*70)
print(classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
print("\nğŸ”¢ CONFUSION MATRIX:")
print("(Rows = Actual Quality, Columns = Predicted Quality)")
print(cm)

plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=sorted(df['quality'].unique()),
            yticklabels=sorted(df['quality'].unique()),
            cbar_kws={'label': 'Number of Wines'})
plt.title('Confusion Matrix - Wine Quality Prediction', fontsize=16, fontweight='bold', pad=20)
plt.xlabel('Predicted Quality', fontsize=12)
plt.ylabel('Actual Quality', fontsize=12)
plt.tight_layout()
plt.show()

print("\n" + "="*70)

print("\nâ­ FEATURE IMPORTANCE ANALYSIS")
print("="*70)
print("(Shows which chemical properties matter most for prediction)\n")

feature_importance = pd.DataFrame({
    'Feature': X.columns,
    'Importance': model.feature_importances_
}).sort_values(by='Importance', ascending=False)

print(feature_importance.to_string(index=False))

print(f"\nğŸ’¡ Key Insight: '{feature_importance.iloc[0]['Feature']}' is the most important feature!")

plt.figure(figsize=(10, 6))
colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(feature_importance)))
plt.barh(feature_importance['Feature'], feature_importance['Importance'], color=colors)
plt.xlabel('Importance Score', fontsize=12)
plt.ylabel('Chemical Properties', fontsize=12)
plt.title('Feature Importance in Wine Quality Prediction', fontsize=14, fontweight='bold')
plt.gca().invert_yaxis()
plt.grid(axis='x', alpha=0.3)
plt.tight_layout()
plt.show()

print("\n" + "="*70)

print("\nğŸŒ³ DECISION TREE VISUALIZATION")
print("="*70)
print("(Showing first 3 levels of the tree for clarity)\n")

plt.figure(figsize=(20, 10))
plot_tree(model,
          feature_names=X.columns,
          class_names=[str(c) for c in sorted(df['quality'].unique())],
          filled=True,
          rounded=True,
          fontsize=10,
          max_depth=3)

plt.title('Decision Tree Structure (First 3 Levels)', fontsize=16, fontweight='bold', pad=20)
plt.tight_layout()
plt.show()

print("âœ… Tree visualization complete!")
print("\nğŸ’¡ How to read the tree:")
print("   - Each box shows a decision rule (e.g., 'alcohol <= 10.5')")
print("   - Colors indicate predicted quality (darker = better quality)")
print("   - Follow the branches to see how predictions are made")
print("\n" + "="*70)

print("\nğŸ§ª TESTING WITH A SAMPLE WINE")
print("="*70)

sample_wine = X_test.iloc[0:1]
actual_quality = y_test.iloc[0]

print("\nğŸ“‹ Sample Wine Chemical Properties:")
print(sample_wine.T.to_string(header=False))

predicted_quality = model.predict(sample_wine)[0]

print(f"\nğŸ”® Predicted Quality: {predicted_quality} / 10")
print(f"âœ… Actual Quality: {actual_quality} / 10")

if predicted_quality == actual_quality:
    print(f"ğŸ¯ Prediction is CORRECT! âœ“")
else:
    diff = abs(predicted_quality - actual_quality)
    print(f"âŒ Prediction is off by {diff} point(s)")

print("\n" + "="*70)

print("\n" + "="*70)
print("ğŸ“Š PROJECT SUMMARY")
print("="*70)
print(f"""
âœ… Dataset: UCI Wine Quality Dataset
âœ… Total Samples: {len(df)} red wines
âœ… Features Used: {len(X.columns)} chemical properties
âœ… Model Algorithm: Decision Tree Classifier
âœ… Model Accuracy: {accuracy * 100:.2f}%
âœ… Most Important Feature: {feature_importance.iloc[0]['Feature']}
âœ… Training Samples: {len(X_train)}
âœ… Testing Samples: {len(X_test)}
""")
print("="*70)
print("âœ… ANALYSIS COMPLETE! Ready for GitHub and Streamlit!")
print("="*70)